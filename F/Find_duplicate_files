#!/usr/bin/env perl6
#u# http://rosettacode.org/wiki/Find_duplicate_files
#c# 2017-06-03 <RC, 2017-07-23 >RC
#m# MOAR: OK
#j#  JVM: BROKEN
#n# 2022-07-05 call to call for digest generation was 'backwards', need 'sha256-hex'

use Digest::SHA256::Native;

sub MAIN( $dir = 'bin', :$minsize = 5, :$recurse = True ) {
    my %files;
    my @dirs = $dir.IO.absolute.IO;
    while @dirs {
        my @files = @dirs.pop;
        while @files {
            for @files.pop.dir -> $path {
                %files{ $path.s }.push: $path if $path.f and $path.s >= $minsize;
                @dirs.push: $path if $path.d and $path.r and $recurse
            }
        }
    }

    my @res;
    for %files.sort( +*.key ).grep( *.value.elems > 1)».kv -> ($size, @list) {
        my %dups;
        @list.map: { %dups{ sha256-hex( ($_.slurp :bin).decode ) }.push: $_.Str };
        for %dups.grep( *.value.elems > 1)».value -> @dups {
            @res.push: sprintf("%9s : ", scale $size ) ~ @dups.join(', ');
        }
    }
    .say for @res;

    use Test;
    ok @res ~~ m['rc-jvm'] and @res ~~ m['rc-moar'];
}

sub scale ($bytes) {
    given $bytes {
        when $_ < 2**10 {  $bytes                    ~ ' B'  }
        when $_ < 2**20 { ($bytes / 2**10).round(.1) ~ ' KB' }
        when $_ < 2**30 { ($bytes / 2**20).round(.1) ~ ' MB' }
        default         { ($bytes / 2**30).round(.1) ~ ' GB' }
    }
}
